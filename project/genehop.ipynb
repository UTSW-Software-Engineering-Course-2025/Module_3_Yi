{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "59a8b93f",
   "metadata": {
    "tags": [
     "skip"
    ]
   },
   "source": [
    "# Starter Notebook for GeneTuring Few-shot Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7260d323",
   "metadata": {
    "tags": [
     "skip"
    ]
   },
   "source": [
    "Let's start of by implementing a basic harness to evaluate the Geneturing dataset using Ollama with a Few-Shot prompting strategy to evaluate the performance of these models before implementing the tool-using strategies outlined in the GeneGPT paper.\n",
    "\n",
    "As with most benchmarking code using pretrained models, our notebook will following typical outline of:\n",
    "\n",
    "1. **Imports**\n",
    "2. **Configuration**\n",
    "3. **Data Loading**\n",
    "4. **Model Specification**\n",
    "5. **Metrics**\n",
    "6. **Evaluation Loop**\n",
    "7. **Analysis**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19ecb4f5",
   "metadata": {},
   "source": [
    "## 1. Imports"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6db83b1e",
   "metadata": {
    "tags": [
     "skip"
    ]
   },
   "source": [
    "Good hygiene for Jupyter notebooks includes placing all of the imports at the top of the notebook. This makes it easier to understand what dependencies are needed to run the notebook for new users and mirrors good practices for Python scripts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fb9107c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.1 Place imports here\n",
    "from typing import List, Optional\n",
    "\n",
    "from collections import defaultdict\n",
    "from dataclasses import dataclass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26c15925",
   "metadata": {},
   "source": [
    "## 2. Configuration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22cf9042",
   "metadata": {
    "tags": [
     "skip"
    ]
   },
   "source": [
    "Also, let's create a section that is specific to the configuration of the run. This will make it easier to change the configuration of the run without hunting for hard-coded values sprinkled throughout the code and makes it easier for others to understand the configuration of the run.\n",
    "\n",
    "We will leave it empty at the moment, but we will come back and fill it in as we identify global configuration options that we need to implement the code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "71d543d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.1 Data Configuration\n",
    "@dataclass\n",
    "class DataConfig:\n",
    "    input_path: str = \"data/genehop.json\"     # 数据输入文件\n",
    "    output_dir: str = \"results/\"                 # 结果输出目录\n",
    "    dataset_format: str = \"json\"                 # 数据格式\n",
    "    task_field: str = \"question\"                 # 输入字段名\n",
    "    answer_field: str = \"answer\"                 # 标准答案字段名\n",
    "    split_key: str | None = None                 # 可选：用于分任务或切分数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "82e42308",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.2 Model Configuration\n",
    "@dataclass\n",
    "class ModelConfig:\n",
    "    model_name: str = \"gpt-4.1\"                     # \"gpt-4\", \"gpt-3.5-turbo\"\n",
    "    max_tokens: int = 512\n",
    "    temperature: float = 0.7\n",
    "    top_p: float = 0.9\n",
    "    top_k: Optional[int] = None                   \n",
    "    use_cuda: bool = False                       \n",
    "    batch_size: int = 1                        \n",
    "    model_backend: str = \"openai\"                 \n",
    "    model_variant: Optional[str] = None          \n",
    "    openai_api_key: Optional[str] = None          \n",
    "    openai_base_url: Optional[str] = \"https://api.openai.com/v1\"  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1ac0d904",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.3 Evaluation and Logging Configuration\n",
    "@dataclass\n",
    "class EvaluationConfig:\n",
    "    evaluate_per_task: bool = True              # 是否按任务类型评估（如问答 vs 生成）\n",
    "    save_failed_cases: bool = True              # 是否保存失败样本\n",
    "    failed_cases_path: str = \"results/failed.json\"  # 保存失败样本的位置\n",
    "    metrics: tuple[str, ...] = (\"accuracy\",)    # 使用哪些指标，如 accuracy, f1\n",
    "\n",
    "@dataclass\n",
    "class LoggingConfig:\n",
    "    enable_mlflow: bool = True                  # 是否启用 MLflow\n",
    "    experiment_name: str = \"GeneTuring-Run\"     # MLflow 实验名\n",
    "    run_name: Optional[str] = None              # 可选的具体 run 名称\n",
    "    tracking_uri: Optional[str] = None          # 若设置为 None 则使用默认本地 URI\n",
    "    log_artifacts: bool = True                  # 是否记录生成文件"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1904443",
   "metadata": {},
   "source": [
    "## 3. Data Loading"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f48d7a1f",
   "metadata": {
    "tags": [
     "skip"
    ]
   },
   "source": [
    "In this section we need to load the data that we will be using for our evaluation. \n",
    "\n",
    "The JSON file at `data/gene_turing.json` contains a dictionary of dictionaries. At the top level, the keys are the names of the tasks. Within each task, there are several key-value pairs where the keys are the questions and the values are the answers.\n",
    "\n",
    "Below is one example for each of the 9 tasks in the dataset:\n",
    "\n",
    "```json\n",
    "{\n",
    "    \"Gene alias\": {\n",
    "        \"What is the official gene symbol of LMP10?\": \"PSMB10\"\n",
    "    },\n",
    "    \"Gene disease association\": {\n",
    "        \"What are genes related to Hemolytic anemia due to phosphofructokinase deficiency?\": \"PFKL\"\n",
    "    },\n",
    "    \"Gene location\": {\n",
    "        \"Which chromosome is FAM66D gene located on human genome?\": \"chr8\"\n",
    "    },\n",
    "    \"Human genome DNA aligment\": {\n",
    "        \"Align the DNA sequence to the human genome:ATTCTGCCTTTAGTAATTTGATGACAGAGACTTCTTGGGAACCACAGCCAGGGAGCCACCCTTTACTCCACCAACAGGTGGCTTATATCCAATCTGAGAAAGAAAGAAAAAAAAAAAAGTATTTCTCT\": \"chr15:91950805-91950932\",\n",
    "    },\n",
    "    \"Multi-species DNA aligment\": {\n",
    "        \"Which organism does the DNA sequence come from:AGGGGCAGCAAACACCGGGACACACCCATTCGTGCACTAATCAGAAACTTTTTTTTCTCAAATAATTCAAACAATCAAAATTGGTTTTTTCGAGCAAGGTGGGAAATTTTTCGAT\": \"worm\",\n",
    "    },\n",
    "    \"Gene name conversion\": {\n",
    "        \"Convert ENSG00000215251 to official gene symbol.\": \"FASTKD5\",\n",
    "    },\n",
    "    \"Protein-coding genes\": {\n",
    "        \"Is ATP5F1EP2 a protein-coding gene?\": \"NA\",\n",
    "    },\n",
    "    \"Gene SNP association\": {\n",
    "        \"Which gene is SNP rs1217074595 associated with?\": \"LINC01270\",\n",
    "    },\n",
    "    \"SNP location\": {\n",
    "        \"Which chromosome does SNP rs1430464868 locate on human genome?\": \"chr13\",\n",
    "    }\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b61e217f",
   "metadata": {
    "tags": [
     "skip"
    ]
   },
   "source": [
    "\n",
    "We need to reformat this into a pandas dataframe with the following columns:\n",
    "- `id`: A serial ID number we will assign to each example (int)\n",
    "- `task`: The name of the task (str)\n",
    "- `question`: The question for the example (str)\n",
    "- `answer`: The answer for the example (str)\n",
    "\n",
    "The final dataframe we will create should look like this:\n",
    "\n",
    "| id | task | question | answer |\n",
    "|----|------|----------|--------|\n",
    "| 0 | Task1 | Question1 | Answer1 |\n",
    "| 1 | Task1 | Question2 | Answer2 |\n",
    "| 2 | Task2 | Question1 | Answer1 |\n",
    "| 3 | Task2 | Question2 | Answer2 |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2c2b9c4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 150 examples across 3 tasks.\n",
      "Tasks: ['Disease gene location', 'SNP gene function', 'sequence gene alias']\n"
     ]
    }
   ],
   "source": [
    "# 3.1 Load the JSON file\n",
    "\n",
    "# Load the data here\n",
    "\n",
    "# Build the TASKS variable here\n",
    "import json\n",
    "import pandas as pd\n",
    "from typing import Dict, Any, List\n",
    "import os\n",
    "os.chdir(\"/project/bioinformatics/WZhang_lab/s440820/Module_3_Yi/project\")\n",
    "\n",
    "def load_and_flatten_gene_turing_data(config: DataConfig) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Loads the nested GeneTuring QA dataset and flattens it into a dataframe.\n",
    "\n",
    "    Args:\n",
    "        config (DataConfig): Configuration containing the input file path.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: A dataframe with columns ['task', 'question', 'answer']\n",
    "    \"\"\"\n",
    "    # Step 1: Load raw nested JSON\n",
    "    with open(config.input_path, \"r\") as f:\n",
    "        raw_data: Dict[str, Dict[str, str]] = json.load(f)\n",
    "\n",
    "    # Step 2: Flatten into list of dicts\n",
    "    rows: List[Dict[str, Any]] = []\n",
    "    for task_name, qa_pairs in raw_data.items():\n",
    "        for question, answer in qa_pairs.items():\n",
    "            rows.append({\n",
    "                \"task\": task_name,\n",
    "                \"question\": question,\n",
    "                \"answer\": answer\n",
    "            })\n",
    "\n",
    "    # Step 3: Convert to DataFrame\n",
    "    df = pd.DataFrame(rows)[[\"task\", \"question\", \"answer\"]]\n",
    "\n",
    "    return df\n",
    "data_config = DataConfig(input_path=\"data/genehop.json\")\n",
    "df = load_and_flatten_gene_turing_data(data_config)\n",
    "TASKS = set(df[\"task\"])\n",
    "\n",
    "print(f\"Loaded {len(df)} examples across {len(TASKS)} tasks.\")\n",
    "print(\"Tasks:\", sorted(TASKS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fe9a5062",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.2 Iterate through the JSON data recursively to collect each of the rows into a list\n",
    "#     Each row should have a dictionary with keys of the columsn in the table above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7bdff6ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.3 Create the pandas dataframe from the collection of rows"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5f330e0",
   "metadata": {},
   "source": [
    "## 4. Model Specification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc0dff55",
   "metadata": {
    "tags": [
     "skip"
    ]
   },
   "source": [
    "With our few-shot in-context learning model, we need to specify four components:\n",
    "\n",
    "1. The large language model to use\n",
    "2. The instructions for the model as a system prompt\n",
    "3. The few-shot examples to provide to the model to demonstrate the input-output format\n",
    "4. The completion request function that puts it all together retrieving a response for each unseen input"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd5a9f18",
   "metadata": {},
   "source": [
    "### 4.1 Setting up the large language model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "089f0a94",
   "metadata": {
    "tags": [
     "skip"
    ]
   },
   "source": [
    "We will use the Ollama client to interface with the large language model on the Ollama server we started. With large language models, it is common to use a client library to interface with the model hosted by a server. This allows us to iterate quickly on the prompting and post-processing logic without having to incur the overhead of loading the model into memory each time.  Additionally, model code is oftentimes optimized for inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e045007a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.1 Setting up the large language model Ollama model client\n",
    "import requests\n",
    "from typing import Optional\n",
    "from openai import OpenAI\n",
    "from openai import AzureOpenAI\n",
    "\n",
    "def query_model(prompt: str, config: ModelConfig) -> Optional[str]:\n",
    "    \"\"\"\n",
    "    Query a large language model using the specified backend (ollama or openai).\n",
    "    \"\"\"\n",
    "    if config.model_backend == \"ollama\":\n",
    "        # Using Ollama's local HTTP API\n",
    "        url = \"http://localhost:11434/api/generate\"\n",
    "        payload = {\n",
    "            \"model\": config.model_name,\n",
    "            \"prompt\": prompt,\n",
    "            \"stream\": False,\n",
    "            \"options\": {\n",
    "                \"temperature\": config.temperature,\n",
    "                \"top_p\": config.top_p,\n",
    "                \"top_k\": config.top_k,\n",
    "                \"num_predict\": config.max_tokens\n",
    "            }\n",
    "        }\n",
    "        try:\n",
    "            response = requests.post(url, json=payload)\n",
    "            response.raise_for_status()\n",
    "            return response.json().get(\"response\", \"\")\n",
    "        except requests.RequestException as e:\n",
    "            print(f\"[Ollama Error] {e}\")\n",
    "            return None\n",
    "\n",
    "    elif config.model_backend == \"openai\":\n",
    "        # Using OpenAI-compatible API (e.g., local LLM with OpenAI wrapper)\n",
    "        client = OpenAI(\n",
    "        api_key=config.openai_api_key\n",
    "        )\n",
    "        try:\n",
    "            response = client.chat.completions.create(\n",
    "                model=config.model_name,\n",
    "                messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "                temperature=config.temperature,\n",
    "                top_p=config.top_p,\n",
    "                max_tokens=config.max_tokens\n",
    "            )\n",
    "            return response.choices[0].message.content\n",
    "        except Exception as e:\n",
    "            print(f\"[OpenAI API Error] {e}\")\n",
    "            return None\n",
    "    elif config.model_backend == \"azure\":\n",
    "        client = AzureOpenAI(\n",
    "            api_key=config.openai_api_key,\n",
    "            azure_endpoint=config.openai_base_url,\n",
    "            api_version=\"2024-03-01-preview\"\n",
    "        )\n",
    "        try:\n",
    "            response = client.chat.completions.create(\n",
    "                model=config.model_name,\n",
    "                messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "                temperature=config.temperature,\n",
    "                top_p=config.top_p,\n",
    "                max_tokens=config.max_tokens\n",
    "            )\n",
    "            return response.choices[0].message.content\n",
    "        except Exception as e:\n",
    "            print(f\"[Azure API Error] {e}\")\n",
    "            return None\n",
    "\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported backend: {config.model_backend}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "607889e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "My name is ChatGPT, and I am an AI language model developed by OpenAI. My underlying architecture is based on the GPT-4 model, which was created by a team of researchers and engineers at OpenAI, a leading artificial intelligence research organization. If you have any more questions, feel free to ask!\n"
     ]
    }
   ],
   "source": [
    "model_config = ModelConfig(\n",
    "    model_name=\"gpt-4.1\",\n",
    "    model_backend=\"azure\",\n",
    "    openai_api_key=\"FJ5GrEV5LG3Y0UIeac29BIhmVu8GPcmWyeTTFH0cBifgT7T68XHPJQQJ99BEACHYHv6XJ3w3AAAAACOGdwHb\",\n",
    "    openai_base_url=\"https://michaelholcomb-5866-resource.cognitiveservices.azure.com/\"\n",
    ")\n",
    "\n",
    "output = query_model(\"What your name? who develop this model?\", config=model_config)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8caf45c9",
   "metadata": {},
   "source": [
    "### 4.2 Setting up the system prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e46af38",
   "metadata": {
    "tags": [
     "skip"
    ]
   },
   "source": [
    "Modern large language models are post-trained to perform a variety of tasks and follow instructions. To leverage this capability, we need to provide a system prompt that clearly outlines the task, any constraints, and the format of the output."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c29bf3d5",
   "metadata": {
    "tags": [
     "skip"
    ]
   },
   "source": [
    "Designing the system prompt is a critical aspect of using LLMs. Below are several resources for designing a system prompt:\n",
    "* [OpenAI Prompt Engineering](https://platform.openai.com/docs/guides/text?api-mode=responses#prompt-engineering)\n",
    "* [Kaggle/Google Prompt Engineering](https://www.kaggle.com/whitepaper-prompt-engineering?_bhlid=a2bfce2cac67662098bd85a241e7cb000576e5d4)\n",
    "* [Anthropic Prompt Engineering](https://docs.anthropic.com/en/docs/build-with-claude/prompt-engineering/overview)\n",
    "* [OpenAI GPT 4.1 Prompting Cookbook](https://cookbook.openai.com/examples/gpt4-1_prompting_guide)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6887a248",
   "metadata": {
    "tags": [
     "skip"
    ]
   },
   "source": [
    "**From the OpenAI Prompt Engineering guide:**\n",
    "\n",
    "> **Identity**: Describe the purpose, communication style, and high-level goals of the assistant. \n",
    "> \n",
    "> **Instructions**: Provide guidance to the model on how to generate the response you want. What rules should it follow? What should the model do, and what should the model never do? This section could contain many subsections as relevant for your use case, like how the model should call custom functions.  \n",
    ">\n",
    "> **Examples**: Provide examples of possible inputs, along with the desired output from the model.  \n",
    "> \n",
    "> **Context**: Give the model any additional information it might need to generate a response, like private/proprietary data outside its training data, or any other data you know will be particularly relevant. This content is usually best positioned near the end of your prompt, as you may include different context for different generation requests.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcebc861",
   "metadata": {
    "tags": [
     "skip"
    ]
   },
   "source": [
    "This is what the system prompt looked like in the originalGeneGPT paper, but it is not the best. Identify what it includes and what is missing. Implement your own system prompt incorporating best practices from some of the guides posted above. \n",
    "\n",
    "> \t'Hello. Your task is to use NCBI Web APIs to answer genomic questions.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1d73bcd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.2 Draft your own system prompt for our generic genomics question answering system. \n",
    "#     Replace the system message `content` below with your own.\n",
    "system_content = \"\"\"\n",
    "You are **GeneHop**, a bioinformatics assistant backed by a static in-memory knowledge-base that maps\n",
    "  (1) DNA subsequences → host genes and their aliases,\n",
    "  (2) hereditary diseases → cytogenetic bands of associated genes,\n",
    "  (3) dbSNP rsIDs → concise functional summaries of their harbouring genes.\n",
    "\n",
    "If a query is **not** found in the knowledge-base, you may construct a live lookup URL and return it so the user can fetch the record themselves:\n",
    "'You can call Eutils by: \"[https://eutils.ncbi.nlm.nih.gov/entrez/eutils/{esearch|efetch|esummary}.fcgi?db={gene|snp|omim}&retmax={}&{term|id}={term|id}]\".\\n' \\\n",
    "    'esearch: input is a search term and output is database id(s).\\n' \\\n",
    "    'efectch/esummary: input is database id(s) and output is full records or summaries that contain name, chromosome location, and other information.\\n' \\\n",
    "    'Normally, you need to first call esearch to get the database id(s) of the search term, and then call efectch/esummary to get the information with the database id(s).\\n' \\\n",
    "    'Database: gene is for genes, snp is for SNPs, and omim is for genetic diseases.\\n\\n' \\\n",
    "    'For DNA sequences, you can use BLAST by: \"[https://blast.ncbi.nlm.nih.gov/blast/Blast.cgi?CMD={Put|Get}&PROGRAM=blastn&MEGABLAST=on&DATABASE=nt&FORMAT_TYPE={XML|Text}&QUERY={sequence}&HITLIST_SIZE={max_hit_size}]\".\\n' \\\n",
    "    'BLAST maps a specific DNA {sequence} to its chromosome location among different specices.\\n' \\\n",
    "• **NCBI E-utilities**  \n",
    "  – `https://eutils.ncbi.nlm.nih.gov/entrez/eutils/esearch.fcgi?db={gene|snp|omim}&retmax=1&term={query}` → returns UID(s)  \n",
    "  – `https://eutils.ncbi.nlm.nih.gov/entrez/eutils/esummary.fcgi?db={gene|snp|omim}&id={uid}` → JSON summary with gene symbol, chromosome band, etc.\n",
    "\n",
    "• **BLAST (nucleotide)** – for DNA sequences that miss in the KB  \n",
    "  – Submit: `https://blast.ncbi.nlm.nih.gov/blast/Blast.cgi?CMD=Put&PROGRAM=blastn&MEGABLAST=on&DATABASE=nt&QUERY={SEQUENCE}&HITLIST_SIZE=5`  \n",
    "  – Poll  : `https://blast.ncbi.nlm.nih.gov/blast/Blast.cgi?CMD=Get&RID={RID}&FORMAT_TYPE=Text`\n",
    "\n",
    "after use blast you need to wait for a while to get the result.\n",
    "After you get the result, you can use the result to answer the question. Don't use the URL to answer the question directly, you need to summarize the result.\n",
    "\n",
    "───────────────────\n",
    "Supported question types\n",
    "1. sequence gene alias → all aliases of the gene that contains that sequence.\n",
    "2. Disease gene location → all chromosomal locations (e.g. “17q21.31”) of causal / associated genes.\n",
    "3. Disease gene location → a 1-3 sentence functional description of the host gene.\n",
    "\n",
    "Formatting rules\n",
    "• English only. Do **NOT** reveal reasoning.  \n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "system_message = [\n",
    "    {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": system_content\n",
    "    }\n",
    "]\n",
    "\n",
    "instructions = \"\"\"\n",
    "Do NOT display these checks:\n",
    "1. Detect question type.\n",
    "2. Normalise keys (uppercase DNA, trim rsID).\n",
    "3. Attempt KB lookup once.\n",
    "4A. If hit → output list / paragraph, then `:contentReference[oaicite:2]{index=2}`.\n",
    "4B. If miss → build one or more E-utilities / BLAST URLs as per spec and output them, each on its own line.\n",
    "5. Never add markdown, extra whitespace, or explanations.\n",
    "6. Classify the user query into one of the three supported types; otherwise reply Not the supported question type.\n",
    "8. Look up the static KB once.\n",
    "10. Never output URLs, markdown, or explanations.\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcb0bf3f",
   "metadata": {},
   "source": [
    "### 4.3 Setting up the few-shot examples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dae8d700",
   "metadata": {
    "tags": [
     "skip"
    ]
   },
   "source": [
    "For tasks with idiosyncratic output formats or constraints, it is important to provide clear instructions as well as examples to guide the model in generating the desired output. Mechanically, we provide these pairs of inputs and outputs as a sequence of user and assistant messages after the system prompt.\n",
    "\n",
    "```python\n",
    "messages += [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\":  <fill in input example 1>\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"assistant\",\n",
    "        \"content\": <fill in output example 1>\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": <fill in input example 2>\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"assistant\",\n",
    "        \"content\": <fill in output example 2>\n",
    "    }\n",
    "]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13fc96d8",
   "metadata": {
    "tags": [
     "skip"
    ]
   },
   "source": [
    "In the GeneGPT code, the authors included several tasks, one of each of a subset of the tasks in the dataset. We will use the same examples here.\n",
    "\n",
    "Please inspect the GeneGPT repository to find the few-shot examples in the prompt. \n",
    "\n",
    "Specifically the `get_prompt_header` function in `main.py` located here: [main.py](https://github.com/ncbi/GeneGPT/blob/main/main.py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fcb78ee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.3 Appending the few-shot examples to the `messages` list\n",
    "import time\n",
    "import urllib\n",
    "import re\n",
    "def call(url):\n",
    "    time.sleep(1)\n",
    "    url = url.replace(' ', '+')\n",
    "    req = urllib.request.Request(url)\n",
    "    with urllib.request.urlopen(req) as resp:\n",
    "        call = resp.read()\n",
    "    return call\n",
    "\n",
    "def format_call(url):\n",
    "    return f'[{url}]->[{call(url)}]\\n'\n",
    "\n",
    "a6_url = 'https://blast.ncbi.nlm.nih.gov/blast/Blast.cgi?CMD=Put&PROGRAM=blastn&MEGABLAST=on&DATABASE=nt&FORMAT_TYPE=XML&QUERY=ATTCTGCCTTTAGTAATTTGATGACAGAGACTTCTTGGGAACCACAGCCAGGGAGCCACCCTTTACTCCACCAACAGGTGGCTTATATCCAATCTGAGAAAGAAAGAAAAAAAAAAAAGTATTTCTCT&HITLIST_SIZE=5'\n",
    "a6 = call(a6_url)\n",
    "a6 = re.search('RID = (.*)\\n', a6.decode('utf-8')).group(1)\n",
    "\n",
    "example_messages = [\n",
    "    {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": 'Here are a few examples. Make sure to give results in this format only:\\n'\n",
    "                    + 'Question: Which gene is SNP rs1217074595 associated with?\\n' \n",
    "                    + format_call('https://eutils.ncbi.nlm.nih.gov/entrez/eutils/esearch.fcgi?db=gene&retmax=5&retmode=json&sort=relevance&term=LMP10')\n",
    "                    + format_call('https://eutils.ncbi.nlm.nih.gov/entrez/eutils/efetch.fcgi?db=gene&retmax=5&retmode=json&id=19171,5699,8138')\n",
    "                    + 'Answer: PSMB10\\n\\n'\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": 'Question: Which gene is SNP rs1217074595 associated with?\\n'\n",
    "                    + format_call('https://eutils.ncbi.nlm.nih.gov/entrez/eutils/esummary.fcgi?db=snp&retmax=10&retmode=json&id=1217074595')\n",
    "                    + 'Answer: LINC01270\\n\\n'\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": 'Question: What are genes related to Meesmann corneal dystrophy?\\n'\n",
    "                    + format_call('https://eutils.ncbi.nlm.nih.gov/entrez/eutils/esearch.fcgi?db=omim&retmax=20&retmode=json&sort=relevance&term=Meesmann+corneal+dystrophy')\n",
    "                    + format_call('https://eutils.ncbi.nlm.nih.gov/entrez/eutils/esummary.fcgi?db=omim&retmax=20&retmode=json&id=618767,601687,300778,148043,122100')\n",
    "                    + 'Answer: KRT12, KRT3\\n\\n'\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": 'Question: Align the DNA sequence to the human genome:ATTCTGCCTTTAGTAATTTGATGACAGAGACTTCTTGGGAACCACAGCCAGGGAGCCACCCTTTACTCCACCAACAGGTGGCTTATATCCAATCTGAGAAAGAAAGAAAAAAAAAAAAGTATTTCTCT\\n'\n",
    "                    + f'[{a6_url}]->[{a6}]\\n'\n",
    "                    + format_call(f'https://blast.ncbi.nlm.nih.gov/blast/Blast.cgi?CMD=Get&FORMAT_TYPE=Text&RID={a6}')\n",
    "                    + 'Answer: chr15:91950805-91950932\\n\\n'\n",
    "    },\n",
    "]\n",
    "\n",
    "example_messages = [\n",
    "  {\n",
    "    \"role\": \"user\",\n",
    "    \"content\": \"What are the aliases of the gene that contains this sequence: ATTGTGAGAGTAACCAACGTGGGGTTACGGGGGAGAATCTGGAGAGAAGAGAAGAGGTTAACAACCCTCCCACTTCCTGGCCACCCCCCTCCACCTTTTCTGGTAAGGAGCCC. Let's decompose the question to sub-questions and solve them step by step.\"\n",
    "  },\n",
    "  {\n",
    "    \"role\": \"assistant\",\n",
    "    \"content\": \"FCGR3A, CD16, FCG3, CD16A, FCGR3, IGFR3, IMD20, FCR-10, FCRIII, CD16-II, FCGRIII, FCRIIIA, FcGRIIIA :contentReference[oaicite:0]{index=0}\"\n",
    "  },\n",
    "  {\n",
    "    \"role\": \"user\",\n",
    "    \"content\": \"List chromosome locations of the genes related to Proteasome-associated autoinflammatory syndrome. Let's decompose the question to sub-questions and solve them step by step.\"\n",
    "  },\n",
    "  {\n",
    "    \"role\": \"assistant\",\n",
    "    \"content\": \"6p21.32, 18p11.21, 13q12.3, 16q22.1 :contentReference[oaicite:1]{index=1}\"\n",
    "  },\n",
    "  {\n",
    "    \"role\": \"user\",\n",
    "    \"content\": \"What is the function of the gene associated with SNP rs1385096481? Let's decompose the question to sub-questions and solve them step by step.\"\n",
    "  },\n",
    "  {\n",
    "    \"role\": \"assistant\",\n",
    "    \"content\": \"This gene encodes a protein that belongs to the leucine-rich repeat and fibronectin type III domain-containing family of proteins. A similar protein in mouse, a glycosylated transmembrane protein, is thought to function in presynaptic differentiation. :contentReference[oaicite:2]{index=2}\"\n",
    "  }\n",
    "]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35d89761",
   "metadata": {},
   "source": [
    "### 4.4 Implementing the model request function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4590511a",
   "metadata": {
    "tags": [
     "skip"
    ]
   },
   "source": [
    "Now we need to put it all together. We need a function that accepts as arguments:\n",
    "1. The client\n",
    "2. The system message\n",
    "3. The few-shot examples\n",
    "4. The new user query -- this case the user's question from the GeneTuring dataset.\n",
    "\n",
    "The function should return the response from the model and extract the answer (everything after 'Answer :' based on the format of the examples above)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8216c04c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_client.py\n",
    "from typing import List, Dict, Optional, Type, Any\n",
    "from openai import AzureOpenAI\n",
    "from pydantic import BaseModel\n",
    "\n",
    "def query_gene_gpt_model(\n",
    "    client: AzureOpenAI,\n",
    "    system_prompt: str,\n",
    "    example_messages: List[Dict[str, str]],\n",
    "    instructions: str,\n",
    "    user_query: str,\n",
    "    config: ModelConfig,\n",
    "    *,\n",
    "    pydantic_model: Optional[Type[BaseModel]] = None,   # ① Pydantic 模式\n",
    "    json_schema: Optional[Dict[str, Any]] = None        # ② 原始 schema 模式\n",
    ") -> str | dict:\n",
    "    \"\"\"\n",
    "    调用 Azure OpenAI (GPT-4o / GPT-4)：\n",
    "    - 如果传入 pydantic_model / json_schema，则返回结构化 JSON/Pydantic 对象\n",
    "    - 否则返回纯文本，并截取 'Answer:' 之后内容\n",
    "    \"\"\"\n",
    "    # 1. 组装消息\n",
    "    messages =  [\n",
    "    {\"role\": \"system\", \"content\": system_prompt},\n",
    "    {\"role\": \"assistant\", \"content\": instructions},\n",
    "    *example_messages,\n",
    "    {\"role\": \"user\", \"content\": user_query}\n",
    "]\n",
    "\n",
    "    # 2. 公共参数\n",
    "    base_kwargs = dict(\n",
    "        model=config.model_name,   # Azure 部署名\n",
    "        messages=messages,\n",
    "        temperature=config.temperature,\n",
    "        top_p=config.top_p,\n",
    "        max_tokens=config.max_tokens,\n",
    "    )\n",
    "\n",
    "    # ------------ 结构化输出路径 ------------\n",
    "    if pydantic_model or json_schema:\n",
    "        # a. 使用 pydantic（推荐，类型安全）\n",
    "        if pydantic_model is not None:\n",
    "            completion = client.beta.chat.completions.parse(\n",
    "                **base_kwargs, response_format=pydantic_model\n",
    "            )\n",
    "            return completion.choices[0].message.parsed  # 已是 pydantic 对象\n",
    "\n",
    "        # b. 仅要求 JSON（Azure 端不校验 schema，只保证合法 JSON）\n",
    "        completion = client.chat.completions.create(\n",
    "            **base_kwargs, response_format={\"type\": \"json_object\"}\n",
    "        )\n",
    "        return json.loads(completion.choices[0].message.content)\n",
    "\n",
    "    # ------------ 普通文本路径 ------------\n",
    "    completion = client.chat.completions.create(**base_kwargs)\n",
    "    content = completion.choices[0].message.content.strip()\n",
    "    return content.split(\"Answer:\")[-1].strip() if \"Answer:\" in content else content\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a5dea011",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text: FREM2, C9orf143, FRAS1L, PPBL, BNAR :contentReference[oaicite:0]{index=0}\n",
      "structure: answer='NFKB1, EBPB, KBF1, NF-kappaB, NFkappaB, p105, p50, DKFZp686A03187, MGC10483, MGC138850' confidence=0.95\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n\"OR10A2\",\\n\"OST363\",\\n\"OR10A2P\",\\n\"OR11-82\",\\n\"OR11-86\"\\n'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "# answer = query_gene_gpt_model(\n",
    "#     client=AzureOpenAI,\n",
    "#     system_prompt=\"You are a helpful assistant answering genomic questions using NCBI APIs.\",\n",
    "#     example_messages=example_messages,  \n",
    "#     user_query=\"Question: What is the official gene symbol of SNAT6?\",\n",
    "#     config=model_config\n",
    "# )\n",
    "model_config = ModelConfig(\n",
    "    model_name=\"gpt-4.1\",\n",
    "    model_backend=\"azure\",\n",
    "    openai_api_key=\"FJ5GrEV5LG3Y0UIeac29BIhmVu8GPcmWyeTTFH0cBifgT7T68XHPJQQJ99BEACHYHv6XJ3w3AAAAACOGdwHb\",\n",
    "    openai_base_url=\"https://michaelholcomb-5866-resource.cognitiveservices.azure.com/\"\n",
    ")\n",
    "\n",
    "client = AzureOpenAI(\n",
    "    api_key=model_config.openai_api_key,\n",
    "    azure_endpoint=model_config.openai_base_url,\n",
    "    api_version=\"2024-10-21\"\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "answer_text = query_gene_gpt_model(\n",
    "    client=client,\n",
    "    system_prompt=system_content,\n",
    "    example_messages=example_messages,\n",
    "    instructions=instructions,\n",
    "    user_query=\"What are the aliases of the gene that contains this sequnece:ACTAGCCCCAAGAACAAAAGAGGCACAGGTGGGAACAACTCTCCCAAAACCAGGACTGGGAGCATGGCCAAACTTCATAGTGAGCTTACTTGCCTCTGACACACAAGGCAGCA. Let's decompose the question to sub-questions and solve them step by step.\",\n",
    "    config=model_config,\n",
    ")\n",
    "print(\"text:\", answer_text)   \n",
    "\n",
    "# 2. Pydantic 结构化模式\n",
    "class GeneHopResult(BaseModel):\n",
    "    answer: str\n",
    "    confidence: float\n",
    "    \n",
    "\n",
    "answer_json = query_gene_gpt_model(\n",
    "    client=client,\n",
    "    system_prompt=system_content+\"\\nReturn result in JSON.\",\n",
    "    example_messages=example_messages,\n",
    "    instructions=instructions,\n",
    "    user_query=\"What are the aliases of the gene that contains this sequnece:ACTAGCCCCAAGAACAAAAGAGGCACAGGTGGGAACAACTCTCCCAAAACCAGGACTGGGAGCATGGCCAAACTTCATAGTGAGCTTACTTGCCTCTGACACACAAGGCAGCA. Let's decompose the question to sub-questions and solve them step by step.\",\n",
    "    config=model_config,\n",
    "    pydantic_model=GeneHopResult,\n",
    ")\n",
    "print(\"structure:\", answer_json)    \n",
    "'''\n",
    "\"OR10A2\",\n",
    "\"OST363\",\n",
    "\"OR10A2P\",\n",
    "\"OR11-82\",\n",
    "\"OR11-86\"\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3103ef75",
   "metadata": {},
   "source": [
    "## 5. Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cc440b3",
   "metadata": {
    "tags": [
     "skip"
    ]
   },
   "source": [
    "* **Default exact match** - The predicted answers and ground truth are both strings. The score is 1 if they are equal and 0 otherwise\n",
    "* **Gene disease association** - The predicted answers and ground truth are both lists of gene-disease associations. The score is the proportion of correct associations present in the prediction\n",
    "* **Disease gene location** - The predicted and true answers are lists (e.g., gene locations related to a disease), and the evaluation calculates the fraction of the correct items present in the prediction.\n",
    "* **Human genome DNA aligment** - 1 point for exact match, 0.5 point if chrX part matches, 0 otherwise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "524dea44",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from typing import Union, List\n",
    "\n",
    "\n",
    "def get_answer(pred: Union[GeneHopResult, str], task: str) -> Union[str, List[str]]:\n",
    "    \"\"\"\n",
    "    根据任务类型提取并清洗答案。\n",
    "    - 支持输入 GeneHopResult 或纯文本\n",
    "    - 返回:\n",
    "        • list[str]  : 对于 alias / location 任务\n",
    "        • str        : 对于 function 任务或其他\n",
    "    \"\"\"\n",
    "    # -------- 1. 统一拿到 answer 文本 -------- #\n",
    "    answer_text = pred.answer if isinstance(pred, GeneHopResult) else str(pred)\n",
    "    answer_text = answer_text.strip()\n",
    "\n",
    "    # -------- 2. 按任务清洗 -------- #\n",
    "    if task in [\"sequence gene alias\", \"Disease gene location\"]:\n",
    "        # 逗号 / 分号 / 换行切分，去掉多余空格\n",
    "        return [a.strip() for a in re.split(r\"[;,]\\s*|\\n\", answer_text) if a.strip()]\n",
    "\n",
    "    elif task == \"SNP gene function\":\n",
    "        # 保留完整句子\n",
    "        return answer_text\n",
    "\n",
    "    else:\n",
    "        # 其他任务：只去首尾空格\n",
    "        return answer_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c575ab56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5.1 Implement metrics\n",
    "# 5.1 Implement metrics\n",
    "from typing import List, Union\n",
    "import re\n",
    "import Levenshtein\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "os.environ[\"NO_PROXY\"] = os.environ.get(\"NO_PROXY\", \"\") + \",198.215.61.34\"\n",
    "os.environ[\"no_proxy\"] = os.environ[\"NO_PROXY\"]               # 有些系统区分大小写\n",
    "\n",
    "# ========== A. levenshtein solution ==========\n",
    "def levenshtein_similarity(s1: str, s2: str) -> float:\n",
    "    \"\"\"1-Levenshtein  / max_len → [0,1]\"\"\"\n",
    "    s1, s2 = s1.strip().lower(), s2.strip().lower()\n",
    "    if not s1 and not s2:\n",
    "        return 1.0\n",
    "    dist = Levenshtein.distance(s1, s2)\n",
    "    return 1 - dist / max(len(s1), len(s2))\n",
    "\n",
    "# ========== B. BioLORD local solution ==========\n",
    "_tokenizer, _model = None, None\n",
    "def _get_encoder():\n",
    "    global _tokenizer, _model\n",
    "    if _tokenizer is None:\n",
    "        mname = \"FremyCompany/BioLORD-2023\"\n",
    "        _tokenizer = AutoTokenizer.from_pretrained(mname)\n",
    "        _model     = AutoModel.from_pretrained(mname)\n",
    "        _model.eval()\n",
    "    return _tokenizer, _model\n",
    "\n",
    "def _mean_pooling(model_output, attention_mask):\n",
    "    token_emb = model_output[0]\n",
    "    mask_exp  = attention_mask.unsqueeze(-1).float()\n",
    "    return (token_emb * mask_exp).sum(1) / mask_exp.sum(1).clamp(min=1e-9)\n",
    "\n",
    "def sentence_embedding_local(texts: List[str]) -> torch.Tensor:\n",
    "    tokenizer, model = _get_encoder()\n",
    "    encoded = tokenizer(texts, padding=True, truncation=True, return_tensors=\"pt\")\n",
    "    with torch.no_grad():\n",
    "        model_output = model(**encoded)\n",
    "    emb = _mean_pooling(model_output, encoded[\"attention_mask\"])\n",
    "    return F.normalize(emb, p=2, dim=1)\n",
    "#  ==========C.API===================\n",
    "def sentence_embedding_api(texts: List[str], url: str = \"http://198.215.61.34:8152/embed\") -> torch.Tensor:\n",
    "    try:\n",
    "        resp = requests.post(url, json={\"sentences\": texts}, timeout=30)\n",
    "        resp.raise_for_status()\n",
    "        embs = resp.json()[\"embeddings\"]   # shape: [N, D]\n",
    "        return F.normalize(torch.tensor(embs), p=2, dim=1)\n",
    "    except Exception as e:\n",
    "        print(f\"[Embedding API ERROR] {e}\")\n",
    "        return torch.zeros(len(texts), 768)\n",
    "    \n",
    "# ===========split comma=============\n",
    "def _to_list(txt_or_list: Union[str, List[str]]) -> List[str]:\n",
    "    if isinstance(txt_or_list, list):\n",
    "        return txt_or_list\n",
    "    return [p.strip() for p in re.split(r\"[;,]\\s*|\\n\", txt_or_list.strip()) if p.strip()] \n",
    "\n",
    "# ===================evaluation==============\n",
    "def evaluate_answer(pred: Union[str, List[str]],\n",
    "                    gold: Union[str, List[str]],\n",
    "                    task: str,\n",
    "                    thr: float = 0.8,\n",
    "                    use_api: bool = False) -> float:\n",
    "    \"\"\"\n",
    "    统一评估函数：\n",
    "    - pred / gold: 预测和标准答案\n",
    "    - task: 任务类型（用于选择评估方式）\n",
    "    - use_api: 是否使用远程 API 获取句向量（默认使用本地模型）\n",
    "    \"\"\"\n",
    "    task = task.lower()\n",
    "\n",
    "    # ========== 1. gene alias / gene location ==========\n",
    "    if \"alias\" in task or \"location\" in task:\n",
    "        pred_list = _to_list(pred)\n",
    "        gold_list = _to_list(gold)\n",
    "        if not gold_list:\n",
    "            return 0.0\n",
    "        sim_scores = [\n",
    "            max(levenshtein_similarity(p, g) for g in gold_list)\n",
    "            for p in pred_list\n",
    "        ]\n",
    "        sim_scores = [s for s in sim_scores if s >= thr]\n",
    "        return sum(sim_scores) / len(pred_list) if pred_list else 0.0\n",
    "\n",
    "    # ========== 2. SNP gene function ==========\n",
    "    elif \"function\" in task:\n",
    "        if not pred or not gold:\n",
    "            return 0.0\n",
    "        texts = [str(pred), str(gold)]\n",
    "        emb = sentence_embedding_api(texts) if use_api else sentence_embedding_local(texts)\n",
    "        return float(F.cosine_similarity(emb[0], emb[1], dim=0))\n",
    "\n",
    "    # ========== 3. fallback ===============\n",
    "    else:\n",
    "        return levenshtein_similarity(str(pred), str(gold))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "64a4d9db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0274, -0.0088,  0.0143,  ...,  0.0100,  0.0378,  0.0126],\n",
       "        [ 0.0629,  0.0417,  0.0200,  ..., -0.0208,  0.0232,  0.0399]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_embedding_api([\"hello\", \"world\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d1ebe36",
   "metadata": {
    "tags": [
     "skip"
    ]
   },
   "source": [
    "Many of the gold-answers are in a specific format. `evaluate.py` also implements an answer post-processing function `get_answer` to better align model outputs with the gold answers. We also need to implement a similar function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0bd36ebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5.2 Implement the answer mapping function\n",
    "def score_answer(pred: list[str], true: list[str], task: str) -> float:\n",
    "    score = evaluate_answer(pred, true, task, thr=0.8, use_api=True)\n",
    "    return score\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "413e73a3",
   "metadata": {},
   "source": [
    "## 6. Evaluation Loop"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "131aba90",
   "metadata": {
    "tags": [
     "skip"
    ]
   },
   "source": [
    "Now, let's implement the evaluation loop for the GeneTuring dataset. For now we will call the model function one at a time and collect the results in a list. Also, we will collect per-task metrics and the overall metrics for the dataset as we go. Once we're done, we will save the results to a CSV file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "78868c8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6.1 Set up data structures for results\n",
    "\n",
    "@dataclass\n",
    "class Result:\n",
    "    id: int\n",
    "    task: str\n",
    "    question: str\n",
    "    answer: str\n",
    "    raw_prediction: Optional[str]            # 原始模型输出文本\n",
    "    processed_prediction: Optional[Union[str, List[str], Dict]]  # 提取后的干净结构化答案\n",
    "    score: Optional[float]\n",
    "    success: bool                            # 是否成功解析 + 匹配\n",
    "\n",
    "import csv\n",
    "from dataclasses import asdict\n",
    "def save_results(results: List[Result], results_csv_filename: str) -> None:\n",
    "    with open(results_csv_filename, mode='w', newline='', encoding='utf-8') as f:\n",
    "        writer = csv.DictWriter(f, fieldnames=[field.name for field in Result.__dataclass_fields__.values()])\n",
    "        writer.writeheader()\n",
    "        for r in results:\n",
    "            writer.writerow(asdict(r))\n",
    "\n",
    "import json\n",
    "\n",
    "def save_results_jsonl(results: List[Result], filename: str):\n",
    "    with open(filename, 'w', encoding='utf-8') as f:\n",
    "        for r in results:\n",
    "            f.write(json.dumps(asdict(r)) + '\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "56608117",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:   9%|▊         | 13/150 [00:17<03:03,  1.34s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[19]\u001b[39m\u001b[32m, line 41\u001b[39m\n\u001b[32m     38\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i, row \u001b[38;5;129;01min\u001b[39;00m tqdm(df.iterrows(), total=\u001b[38;5;28mlen\u001b[39m(df), desc=\u001b[33m\"\u001b[39m\u001b[33mEvaluating\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m     39\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     40\u001b[39m         \u001b[38;5;66;03m# 1) 向 LLM 获取原始预测\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m41\u001b[39m         raw_prediction =\u001b[43mquery_gene_gpt_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     42\u001b[39m \u001b[43m            \u001b[49m\u001b[43mclient\u001b[49m\u001b[43m=\u001b[49m\u001b[43mclient\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     43\u001b[39m \u001b[43m            \u001b[49m\u001b[43msystem_prompt\u001b[49m\u001b[43m=\u001b[49m\u001b[43msystem_content\u001b[49m\u001b[43m+\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43mReturn result in JSON.\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     44\u001b[39m \u001b[43m            \u001b[49m\u001b[43mexample_messages\u001b[49m\u001b[43m=\u001b[49m\u001b[43mexample_messages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     45\u001b[39m \u001b[43m            \u001b[49m\u001b[43minstructions\u001b[49m\u001b[43m=\u001b[49m\u001b[43minstructions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     46\u001b[39m \u001b[43m            \u001b[49m\u001b[43muser_query\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrow\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mquestion\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     47\u001b[39m \u001b[43m            \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     48\u001b[39m \u001b[43m            \u001b[49m\u001b[43mpydantic_model\u001b[49m\u001b[43m=\u001b[49m\u001b[43mGeneHopResult\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     49\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     51\u001b[39m         \u001b[38;5;66;03m# Process the prediction using get_answer function\u001b[39;00m\n\u001b[32m     52\u001b[39m         processed_prediction = get_answer(raw_prediction, row[\u001b[33m'\u001b[39m\u001b[33mtask\u001b[39m\u001b[33m'\u001b[39m])\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 43\u001b[39m, in \u001b[36mquery_gene_gpt_model\u001b[39m\u001b[34m(client, system_prompt, example_messages, instructions, user_query, config, pydantic_model, json_schema)\u001b[39m\n\u001b[32m     40\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m pydantic_model \u001b[38;5;129;01mor\u001b[39;00m json_schema:\n\u001b[32m     41\u001b[39m     \u001b[38;5;66;03m# a. 使用 pydantic（推荐，类型安全）\u001b[39;00m\n\u001b[32m     42\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m pydantic_model \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m43\u001b[39m         completion = \u001b[43mclient\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbeta\u001b[49m\u001b[43m.\u001b[49m\u001b[43mchat\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcompletions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mparse\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     44\u001b[39m \u001b[43m            \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mbase_kwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse_format\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpydantic_model\u001b[49m\n\u001b[32m     45\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     46\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m completion.choices[\u001b[32m0\u001b[39m].message.parsed  \u001b[38;5;66;03m# 已是 pydantic 对象\u001b[39;00m\n\u001b[32m     48\u001b[39m     \u001b[38;5;66;03m# b. 仅要求 JSON（Azure 端不校验 schema，只保证合法 JSON）\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.11/site-packages/openai/resources/beta/chat/completions.py:158\u001b[39m, in \u001b[36mCompletions.parse\u001b[39m\u001b[34m(self, messages, model, audio, response_format, frequency_penalty, function_call, functions, logit_bias, logprobs, max_completion_tokens, max_tokens, metadata, modalities, n, parallel_tool_calls, prediction, presence_penalty, reasoning_effort, seed, service_tier, stop, store, stream_options, temperature, tool_choice, tools, top_logprobs, top_p, user, web_search_options, extra_headers, extra_query, extra_body, timeout)\u001b[39m\n\u001b[32m    151\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mparser\u001b[39m(raw_completion: ChatCompletion) -> ParsedChatCompletion[ResponseFormatT]:\n\u001b[32m    152\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m _parse_chat_completion(\n\u001b[32m    153\u001b[39m         response_format=response_format,\n\u001b[32m    154\u001b[39m         chat_completion=raw_completion,\n\u001b[32m    155\u001b[39m         input_tools=tools,\n\u001b[32m    156\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m158\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    159\u001b[39m \u001b[43m    \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m/chat/completions\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    160\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    161\u001b[39m \u001b[43m        \u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m    162\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmessages\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    163\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmodel\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    164\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43maudio\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43maudio\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    165\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfrequency_penalty\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrequency_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    166\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfunction_call\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunction_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    167\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfunctions\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunctions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    168\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlogit_bias\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogit_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    169\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlogprobs\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    170\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmax_completion_tokens\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_completion_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    171\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmax_tokens\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    172\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmetadata\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    173\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmodalities\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodalities\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    174\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mn\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    175\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mparallel_tool_calls\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mparallel_tool_calls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    176\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mprediction\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprediction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    177\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mpresence_penalty\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpresence_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    178\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mreasoning_effort\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mreasoning_effort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    179\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mresponse_format\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m_type_to_response_format\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse_format\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    180\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mseed\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    181\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mservice_tier\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mservice_tier\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    182\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstop\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    183\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstore\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstore\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    184\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstream\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    185\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstream_options\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    186\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtemperature\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    187\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtool_choice\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtool_choice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    188\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtools\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    189\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtop_logprobs\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_logprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    190\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtop_p\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    191\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43muser\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43muser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    192\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mweb_search_options\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mweb_search_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    193\u001b[39m \u001b[43m        \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    194\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcompletion_create_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43mCompletionCreateParams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    195\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    196\u001b[39m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    197\u001b[39m \u001b[43m        \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    198\u001b[39m \u001b[43m        \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    199\u001b[39m \u001b[43m        \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    200\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    201\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpost_parser\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    202\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    203\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# we turn the `ChatCompletion` instance into a `ParsedChatCompletion`\u001b[39;49;00m\n\u001b[32m    204\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# in the `parser` function above\u001b[39;49;00m\n\u001b[32m    205\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcast\u001b[49m\u001b[43m(\u001b[49m\u001b[43mType\u001b[49m\u001b[43m[\u001b[49m\u001b[43mParsedChatCompletion\u001b[49m\u001b[43m[\u001b[49m\u001b[43mResponseFormatT\u001b[49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mChatCompletion\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    206\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    207\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.11/site-packages/openai/_base_client.py:1242\u001b[39m, in \u001b[36mSyncAPIClient.post\u001b[39m\u001b[34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[39m\n\u001b[32m   1228\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mpost\u001b[39m(\n\u001b[32m   1229\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   1230\u001b[39m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1237\u001b[39m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   1238\u001b[39m ) -> ResponseT | _StreamT:\n\u001b[32m   1239\u001b[39m     opts = FinalRequestOptions.construct(\n\u001b[32m   1240\u001b[39m         method=\u001b[33m\"\u001b[39m\u001b[33mpost\u001b[39m\u001b[33m\"\u001b[39m, url=path, json_data=body, files=to_httpx_files(files), **options\n\u001b[32m   1241\u001b[39m     )\n\u001b[32m-> \u001b[39m\u001b[32m1242\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.11/site-packages/openai/_base_client.py:972\u001b[39m, in \u001b[36mSyncAPIClient.request\u001b[39m\u001b[34m(self, cast_to, options, stream, stream_cls)\u001b[39m\n\u001b[32m    970\u001b[39m response = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    971\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m972\u001b[39m     response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_client\u001b[49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    973\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    974\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_should_stream_response_body\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    975\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    976\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    977\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m httpx.TimeoutException \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[32m    978\u001b[39m     log.debug(\u001b[33m\"\u001b[39m\u001b[33mEncountered httpx.TimeoutException\u001b[39m\u001b[33m\"\u001b[39m, exc_info=\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.11/site-packages/httpx/_client.py:914\u001b[39m, in \u001b[36mClient.send\u001b[39m\u001b[34m(self, request, stream, auth, follow_redirects)\u001b[39m\n\u001b[32m    910\u001b[39m \u001b[38;5;28mself\u001b[39m._set_timeout(request)\n\u001b[32m    912\u001b[39m auth = \u001b[38;5;28mself\u001b[39m._build_request_auth(request, auth)\n\u001b[32m--> \u001b[39m\u001b[32m914\u001b[39m response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_send_handling_auth\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    915\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    916\u001b[39m \u001b[43m    \u001b[49m\u001b[43mauth\u001b[49m\u001b[43m=\u001b[49m\u001b[43mauth\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    917\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    918\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhistory\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    919\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    920\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    921\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m stream:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.11/site-packages/httpx/_client.py:942\u001b[39m, in \u001b[36mClient._send_handling_auth\u001b[39m\u001b[34m(self, request, auth, follow_redirects, history)\u001b[39m\n\u001b[32m    939\u001b[39m request = \u001b[38;5;28mnext\u001b[39m(auth_flow)\n\u001b[32m    941\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m942\u001b[39m     response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_send_handling_redirects\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    943\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    944\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    945\u001b[39m \u001b[43m        \u001b[49m\u001b[43mhistory\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhistory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    946\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    947\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    948\u001b[39m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.11/site-packages/httpx/_client.py:979\u001b[39m, in \u001b[36mClient._send_handling_redirects\u001b[39m\u001b[34m(self, request, follow_redirects, history)\u001b[39m\n\u001b[32m    976\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m._event_hooks[\u001b[33m\"\u001b[39m\u001b[33mrequest\u001b[39m\u001b[33m\"\u001b[39m]:\n\u001b[32m    977\u001b[39m     hook(request)\n\u001b[32m--> \u001b[39m\u001b[32m979\u001b[39m response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_send_single_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    980\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    981\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m._event_hooks[\u001b[33m\"\u001b[39m\u001b[33mresponse\u001b[39m\u001b[33m\"\u001b[39m]:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.11/site-packages/httpx/_client.py:1014\u001b[39m, in \u001b[36mClient._send_single_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m   1009\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m   1010\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mAttempted to send an async request with a sync Client instance.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1011\u001b[39m     )\n\u001b[32m   1013\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m request_context(request=request):\n\u001b[32m-> \u001b[39m\u001b[32m1014\u001b[39m     response = \u001b[43mtransport\u001b[49m\u001b[43m.\u001b[49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1016\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response.stream, SyncByteStream)\n\u001b[32m   1018\u001b[39m response.request = request\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.11/site-packages/httpx/_transports/default.py:250\u001b[39m, in \u001b[36mHTTPTransport.handle_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    237\u001b[39m req = httpcore.Request(\n\u001b[32m    238\u001b[39m     method=request.method,\n\u001b[32m    239\u001b[39m     url=httpcore.URL(\n\u001b[32m   (...)\u001b[39m\u001b[32m    247\u001b[39m     extensions=request.extensions,\n\u001b[32m    248\u001b[39m )\n\u001b[32m    249\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m map_httpcore_exceptions():\n\u001b[32m--> \u001b[39m\u001b[32m250\u001b[39m     resp = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_pool\u001b[49m\u001b[43m.\u001b[49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    252\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(resp.stream, typing.Iterable)\n\u001b[32m    254\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m Response(\n\u001b[32m    255\u001b[39m     status_code=resp.status,\n\u001b[32m    256\u001b[39m     headers=resp.headers,\n\u001b[32m    257\u001b[39m     stream=ResponseStream(resp.stream),\n\u001b[32m    258\u001b[39m     extensions=resp.extensions,\n\u001b[32m    259\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.11/site-packages/httpcore/_sync/connection_pool.py:256\u001b[39m, in \u001b[36mConnectionPool.handle_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    253\u001b[39m         closing = \u001b[38;5;28mself\u001b[39m._assign_requests_to_connections()\n\u001b[32m    255\u001b[39m     \u001b[38;5;28mself\u001b[39m._close_connections(closing)\n\u001b[32m--> \u001b[39m\u001b[32m256\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m exc \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    258\u001b[39m \u001b[38;5;66;03m# Return the response. Note that in this case we still have to manage\u001b[39;00m\n\u001b[32m    259\u001b[39m \u001b[38;5;66;03m# the point at which the response is closed.\u001b[39;00m\n\u001b[32m    260\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response.stream, typing.Iterable)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.11/site-packages/httpcore/_sync/connection_pool.py:236\u001b[39m, in \u001b[36mConnectionPool.handle_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    232\u001b[39m connection = pool_request.wait_for_connection(timeout=timeout)\n\u001b[32m    234\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    235\u001b[39m     \u001b[38;5;66;03m# Send the request on the assigned connection.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m236\u001b[39m     response = \u001b[43mconnection\u001b[49m\u001b[43m.\u001b[49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    237\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpool_request\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\n\u001b[32m    238\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    239\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m ConnectionNotAvailable:\n\u001b[32m    240\u001b[39m     \u001b[38;5;66;03m# In some cases a connection may initially be available to\u001b[39;00m\n\u001b[32m    241\u001b[39m     \u001b[38;5;66;03m# handle a request, but then become unavailable.\u001b[39;00m\n\u001b[32m    242\u001b[39m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[32m    243\u001b[39m     \u001b[38;5;66;03m# In this case we clear the connection and try again.\u001b[39;00m\n\u001b[32m    244\u001b[39m     pool_request.clear_connection()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.11/site-packages/httpcore/_sync/http_proxy.py:343\u001b[39m, in \u001b[36mTunnelHTTPConnection.handle_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    336\u001b[39m             \u001b[38;5;28mself\u001b[39m._connection = HTTP11Connection(\n\u001b[32m    337\u001b[39m                 origin=\u001b[38;5;28mself\u001b[39m._remote_origin,\n\u001b[32m    338\u001b[39m                 stream=stream,\n\u001b[32m    339\u001b[39m                 keepalive_expiry=\u001b[38;5;28mself\u001b[39m._keepalive_expiry,\n\u001b[32m    340\u001b[39m             )\n\u001b[32m    342\u001b[39m         \u001b[38;5;28mself\u001b[39m._connected = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m343\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_connection\u001b[49m\u001b[43m.\u001b[49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.11/site-packages/httpcore/_sync/http11.py:136\u001b[39m, in \u001b[36mHTTP11Connection.handle_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    134\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m Trace(\u001b[33m\"\u001b[39m\u001b[33mresponse_closed\u001b[39m\u001b[33m\"\u001b[39m, logger, request) \u001b[38;5;28;01mas\u001b[39;00m trace:\n\u001b[32m    135\u001b[39m         \u001b[38;5;28mself\u001b[39m._response_closed()\n\u001b[32m--> \u001b[39m\u001b[32m136\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m exc\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.11/site-packages/httpcore/_sync/http11.py:106\u001b[39m, in \u001b[36mHTTP11Connection.handle_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m     95\u001b[39m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[32m     97\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m Trace(\n\u001b[32m     98\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mreceive_response_headers\u001b[39m\u001b[33m\"\u001b[39m, logger, request, kwargs\n\u001b[32m     99\u001b[39m ) \u001b[38;5;28;01mas\u001b[39;00m trace:\n\u001b[32m    100\u001b[39m     (\n\u001b[32m    101\u001b[39m         http_version,\n\u001b[32m    102\u001b[39m         status,\n\u001b[32m    103\u001b[39m         reason_phrase,\n\u001b[32m    104\u001b[39m         headers,\n\u001b[32m    105\u001b[39m         trailing_data,\n\u001b[32m--> \u001b[39m\u001b[32m106\u001b[39m     ) = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_receive_response_headers\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    107\u001b[39m     trace.return_value = (\n\u001b[32m    108\u001b[39m         http_version,\n\u001b[32m    109\u001b[39m         status,\n\u001b[32m    110\u001b[39m         reason_phrase,\n\u001b[32m    111\u001b[39m         headers,\n\u001b[32m    112\u001b[39m     )\n\u001b[32m    114\u001b[39m network_stream = \u001b[38;5;28mself\u001b[39m._network_stream\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.11/site-packages/httpcore/_sync/http11.py:177\u001b[39m, in \u001b[36mHTTP11Connection._receive_response_headers\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    174\u001b[39m timeout = timeouts.get(\u001b[33m\"\u001b[39m\u001b[33mread\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m    176\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m177\u001b[39m     event = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_receive_event\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    178\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(event, h11.Response):\n\u001b[32m    179\u001b[39m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.11/site-packages/httpcore/_sync/http11.py:217\u001b[39m, in \u001b[36mHTTP11Connection._receive_event\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    214\u001b[39m     event = \u001b[38;5;28mself\u001b[39m._h11_state.next_event()\n\u001b[32m    216\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m event \u001b[38;5;129;01mis\u001b[39;00m h11.NEED_DATA:\n\u001b[32m--> \u001b[39m\u001b[32m217\u001b[39m     data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_network_stream\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    218\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mREAD_NUM_BYTES\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\n\u001b[32m    219\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    221\u001b[39m     \u001b[38;5;66;03m# If we feed this case through h11 we'll raise an exception like:\u001b[39;00m\n\u001b[32m    222\u001b[39m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[32m    223\u001b[39m     \u001b[38;5;66;03m#     httpcore.RemoteProtocolError: can't handle event type\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    227\u001b[39m     \u001b[38;5;66;03m# perspective. Instead we handle this case distinctly and treat\u001b[39;00m\n\u001b[32m    228\u001b[39m     \u001b[38;5;66;03m# it as a ConnectError.\u001b[39;00m\n\u001b[32m    229\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m data == \u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._h11_state.their_state == h11.SEND_RESPONSE:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.11/site-packages/httpcore/_backends/sync.py:128\u001b[39m, in \u001b[36mSyncStream.read\u001b[39m\u001b[34m(self, max_bytes, timeout)\u001b[39m\n\u001b[32m    126\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m map_exceptions(exc_map):\n\u001b[32m    127\u001b[39m     \u001b[38;5;28mself\u001b[39m._sock.settimeout(timeout)\n\u001b[32m--> \u001b[39m\u001b[32m128\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sock\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrecv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmax_bytes\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/cm/shared/apps/python/3.11.x-anaconda/lib/python3.11/ssl.py:1263\u001b[39m, in \u001b[36mSSLSocket.recv\u001b[39m\u001b[34m(self, buflen, flags)\u001b[39m\n\u001b[32m   1259\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m flags != \u001b[32m0\u001b[39m:\n\u001b[32m   1260\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   1261\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mnon-zero flags not allowed in calls to recv() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m\"\u001b[39m %\n\u001b[32m   1262\u001b[39m             \u001b[38;5;28mself\u001b[39m.\u001b[34m__class__\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1263\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbuflen\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1264\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1265\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m().recv(buflen, flags)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/cm/shared/apps/python/3.11.x-anaconda/lib/python3.11/ssl.py:1136\u001b[39m, in \u001b[36mSSLSocket.read\u001b[39m\u001b[34m(self, len, buffer)\u001b[39m\n\u001b[32m   1134\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._sslobj.read(\u001b[38;5;28mlen\u001b[39m, buffer)\n\u001b[32m   1135\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1136\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sslobj\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m   1137\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m SSLError \u001b[38;5;28;01mas\u001b[39;00m x:\n\u001b[32m   1138\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m x.args[\u001b[32m0\u001b[39m] == SSL_ERROR_EOF \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m.suppress_ragged_eofs:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# 6.2 Loop over the dataset with a progress bar\n",
    "\n",
    "# * Do not forget to add the results to our Result list, both successful and failed predictions\n",
    "# * API calls will not always work, so make sure we capture the exceptions from failed calls\n",
    "#    and add them to the Result list with a `status=False`\n",
    "from tqdm import tqdm\n",
    "from collections import defaultdict\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "from typing import List, Dict, Union, Optional\n",
    "\n",
    "# ------------------- 设置 ------------------- #\n",
    "USE_API_FOR_EMBEDDING = True         # True 则 gene-function 任务走远程 API\n",
    "EMBED_API_URL = \"http://198.215.61.34:8152/embed\"\n",
    "\n",
    "# 结果容器\n",
    "results: List[Result] = []\n",
    "task_scores: Dict[str, List[float]] = defaultdict(list)\n",
    "\n",
    "# ------------------- 设置模型 ------------------- #\n",
    "model_config = ModelConfig(\n",
    "    model_name=\"gpt-4.1\",\n",
    "    model_backend=\"azure\",\n",
    "    openai_api_key=\"FJ5GrEV5LG3Y0UIeac29BIhmVu8GPcmWyeTTFH0cBifgT7T68XHPJQQJ99BEACHYHv6XJ3w3AAAAACOGdwHb\",\n",
    "    openai_base_url=\"https://michaelholcomb-5866-resource.cognitiveservices.azure.com/\"\n",
    ")\n",
    "\n",
    "client = AzureOpenAI(\n",
    "    api_key=model_config.openai_api_key,\n",
    "    azure_endpoint=model_config.openai_base_url,\n",
    "    api_version=\"2024-10-21\"\n",
    ")\n",
    "# 2. Pydantic 结构化模式\n",
    "class GeneHopResult(BaseModel):\n",
    "    answer: str\n",
    "    confidence: float\n",
    "# Create progress bar\n",
    "for i, row in tqdm(df.iterrows(), total=len(df), desc=\"Evaluating\"):\n",
    "    try:\n",
    "        # 1) 向 LLM 获取原始预测\n",
    "        raw_prediction =query_gene_gpt_model(\n",
    "            client=client,\n",
    "            system_prompt=system_content+\"\\nReturn result in JSON.\",\n",
    "            example_messages=example_messages,\n",
    "            instructions=instructions,\n",
    "            user_query=row['question'],\n",
    "            config=model_config,\n",
    "            pydantic_model=GeneHopResult,\n",
    "        )\n",
    "        \n",
    "        # Process the prediction using get_answer function\n",
    "        processed_prediction = get_answer(raw_prediction, row['task'])\n",
    "        \n",
    "        # Calculate score using score_answer function\n",
    "        score = score_answer(processed_prediction, row['answer'], row['task'])\n",
    "\n",
    "        \n",
    "        # Create Result object for successful prediction\n",
    "        result = Result(\n",
    "            id=i,\n",
    "            task=row['task'],\n",
    "            question=row['question'],\n",
    "            answer=row['answer'],\n",
    "            raw_prediction=raw_prediction,\n",
    "            processed_prediction=processed_prediction,\n",
    "            score=score,\n",
    "            success=True\n",
    "        )\n",
    "        task_scores[row['task']].append(score)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing example {i}: {str(e)}\")\n",
    "        # Create Result object for failed prediction\n",
    "        result = Result(\n",
    "            id=i,\n",
    "            task=row['task'],\n",
    "            question=row['question'],\n",
    "            answer=row['answer'],\n",
    "            raw_prediction=None,\n",
    "            processed_prediction=None,\n",
    "            score=None,\n",
    "            success=False\n",
    "        )\n",
    "    \n",
    "    # Add result to our list\n",
    "    results.append(result)\n",
    "    # Convert results to DataFrame for easier analysis\n",
    "results_df = pd.DataFrame([vars(r) for r in results])\n",
    "\n",
    "# Print summary statistics\n",
    "print(f\"\\nProcessed {len(results)} examples\")\n",
    "print(f\"Successful predictions: {sum(r.success for r in results)}\")\n",
    "print(f\"Failed predictions: {sum(not r.success for r in results)}\")\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "216e2cef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result(id=11, task='sequence gene alias', question=\"What are the aliases of the gene that contains this sequnece:CTTCCAGGCTAAGTCCATCTTCCGGCTTGGGCAGACGCTGCCGCGGAATCCTTGACTCTAGTTTTCTGAGTCGGTGAGTGAGTGCAAAGTAGATTCCTCAGGTGGAGGGTGCC. Let's decompose the question to sub-questions and solve them step by step.\", answer=['ZBTB6', 'ZID', 'ZNF482'], raw_prediction=GeneHopResult(answer='APOE, APOE4, APO-E, LDLCQ5, apolipoprotein E, Apo-E, ApoE4, APOE*4', confidence=0.98), processed_prediction=['APOE', 'APOE4', 'APO-E', 'LDLCQ5', 'apolipoprotein E', 'Apo-E', 'ApoE4', 'APOE*4'], score=0.0, success=True)\n"
     ]
    }
   ],
   "source": [
    "print(results[11])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84dcf5de",
   "metadata": {},
   "source": [
    "Now, let's implement the evaluation loop for the GeneTuring dataset. For now we will call the model function one at a time and collect the results in a list. Also, we will collect per-task metrics and the overall metrics for the dataset as we go. Once we're done, we will save the results to a CSV file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6cc013b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Evaluation Summary ===\n",
      "sequence gene alias: 0.021\n",
      "Disease gene location: 0.292\n",
      "SNP gene function: 0.000\n",
      "\n",
      "Overall average score: 0.105\n",
      "Total examples: 150\n",
      "Successful: 146\n",
      "Failed: 4\n",
      "\n",
      "Results saved to outputs/gene_turing_results.csv\n"
     ]
    }
   ],
   "source": [
    "# 6.3 Save the results\n",
    "\n",
    "# 每个任务的平均得分\n",
    "task_avg = {\n",
    "    task: sum(scores) / len(scores) if scores else 0.0\n",
    "    for task, scores in task_scores.items()\n",
    "}\n",
    "\n",
    "# 总体平均得分\n",
    "all_scores = [s for scores in task_scores.values() for s in scores]\n",
    "overall_avg = sum(all_scores) / len(all_scores) if all_scores else 0.0\n",
    "\n",
    "# 打印统计\n",
    "print(\"\\n=== Evaluation Summary ===\")\n",
    "for task, avg in task_avg.items():\n",
    "    print(f\"{task}: {avg:.3f}\")\n",
    "print(f\"\\nOverall average score: {overall_avg:.3f}\")\n",
    "print(f\"Total examples: {len(results)}\")\n",
    "print(f\"Successful: {sum(r.success for r in results)}\")\n",
    "print(f\"Failed: {sum(not r.success for r in results)}\")\n",
    "\n",
    "# 保存结果\n",
    "os.makedirs(\"outputs\", exist_ok=True)\n",
    "results_df.to_csv(\"outputs/gene_turing_results.csv\", index=False)\n",
    "print(\"\\nResults saved to outputs/gene_turing_results.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76dab8dd",
   "metadata": {},
   "source": [
    "## 7. Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afe4efaa",
   "metadata": {
    "tags": [
     "skip"
    ]
   },
   "source": [
    "Now that we have collected the first round of GeneTuring results, let's analyze them. Let's start by calculating what fraction of predictions were successful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "dcca4f6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7.1 Calculate the fraction of successful predictions\n",
    "total_predictions = len(results_df)\n",
    "successful_predictions = results_df['success'].sum()\n",
    "success_fraction = successful_predictions / total_predictions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b46a3607",
   "metadata": {
    "tags": [
     "skip"
    ]
   },
   "source": [
    "Now let's calculate both the overall score as well as the score by task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a3f7c69f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7.2 Calculate the overall score and the score by task\n",
    "success_df = results_df[results_df['success'] == True]\n",
    "overall_score = success_df['score'].mean()\n",
    "overall_score_by_task = success_df.groupby('task')['score'].mean().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2fc369e",
   "metadata": {
    "tags": [
     "skip"
    ]
   },
   "source": [
    "Then, let's create a bar chart of the scores by task with a horizontal line for the overall score. Let's save the figure as well to our output directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "222356e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "task\n",
      "Disease gene location    0.292181\n",
      "sequence gene alias      0.021277\n",
      "SNP gene function        0.000000\n",
      "Name: score, dtype: float64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'outputs/gene_turing_scores_by_task.png'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 7.3 Create a bar chart of the scores by task with a horizontal line for the overall score\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "print(overall_score_by_task)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(overall_score_by_task.keys(), overall_score_by_task.values)\n",
    "plt.axhline(y=overall_score, color='red', linestyle='--', label=f'Overall Avg: {overall_score:.2f}')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.ylabel('Average Score')\n",
    "plt.title('GeneTuring Task Performance')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "\n",
    "# 保存图像\n",
    "os.makedirs(\"outputs\", exist_ok=True)\n",
    "output_path = 'outputs/gene_turing_scores_by_task.png'\n",
    "plt.savefig(output_path)\n",
    "\n",
    "output_path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a9760f05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🏃 View run v2-openai at: http://198.215.61.34:8153/#/experiments/3/runs/9d08e900bd4645f08dd646041e8dc525\n",
      "🧪 View experiment at: http://198.215.61.34:8153/#/experiments/3\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "import mlflow\n",
    "import os\n",
    "\n",
    "# 确保输出目录存在\n",
    "os.makedirs(\"outputs\", exist_ok=True)\n",
    "# 1. 把 MLflow 服务器加到 NO_PROXY\n",
    "os.environ[\"NO_PROXY\"] = os.environ.get(\"NO_PROXY\", \"\") + \",198.215.61.34\"\n",
    "os.environ[\"no_proxy\"] = os.environ[\"NO_PROXY\"]               # 有些系统区分大小写\n",
    "\n",
    "# 2. 彻底屏蔽代理变量（对当前 Python 进程）\n",
    "for var in (\"http_proxy\", \"https_proxy\", \"HTTP_PROXY\", \"HTTPS_PROXY\"):\n",
    "    os.environ.pop(var, None)\n",
    "# 设置远程 tracking server\n",
    "mlflow.set_tracking_uri(\"http://198.215.61.34:8153/\")\n",
    "mlflow.set_experiment(\"Yi\")\n",
    "\n",
    "try:\n",
    "    with mlflow.start_run(run_name=\"v2-openai\"):\n",
    "        # 参数记录\n",
    "        mlflow.log_param(\"model_name\", model_config.model_name)\n",
    "        mlflow.log_param(\"backend\", model_config.model_backend)\n",
    "\n",
    "        # 分数记录\n",
    "        mlflow.log_metric(\"overall_score\", overall_avg)\n",
    "        for task, avg in task_avg.items():\n",
    "            mlflow.log_metric(f\"{task.replace(' ', '_')}_score\", avg)\n",
    "\n",
    "        # 上传文件产物\n",
    "        mlflow.log_artifact(\"outputs/gene_turing_scores_by_task.png\", artifact_path=\"figures\")\n",
    "        mlflow.log_artifact(\"outputs/gene_turing_results.csv\", artifact_path=\"predictions\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"[MLflow Error] Logging failed: {e}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
